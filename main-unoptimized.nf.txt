#!/usr/bin/env nextflow

nextflow.enable.dsl = 2

// Import submodules
include { TRIM_READS_FASTP } from './modules/trim_reads_FASTP.nf'
include { FISH_HLA_READS_BOWTIE2 } from './modules/fish_hla_reads_BOWTIE2.nf'
include { TYPE_HLA_ALLELES_HLAHD } from './modules/type_hla_alleles_HLAHD.nf'
include { CALL_FUSION_TRANSCRIPTS_AR } from './modules/call_fusion_transcripts_AR.nf'
include { CALL_FUSION_TRANSCRIPTS_FC } from './modules/call_fusion_transcripts_FC.nf'
include { PREDICT_CODING_SEQ_AGFUSION } from './modules/predict_coding_seq_AGFUSION.nf'
include { COLLATE_FUSIONS_POLARS } from './modules/collate_fusions_POLARS.nf'
include { ALIGN_READS_STAR } from './modules/align_reads_STAR.nf'
include { CALL_ALT_SPLICING_SPLADDER } from './modules/call_alt_splicing_SPLADDER.nf'

// Function definitions
def helpMessage() {
    log.info"""
Usage:

nextflow run main.nf -profile <local/awsbatch> <--OPTION NAME> <ARGUMENT>

Required Arguments:
---------------
    -profile            Either <local> for testing, or <awsbatch> for AWS Batch cluster [MANDATORY]
    --input_dir         Path to base directory where directories of datasets containing raw fastq or fq files. [MANDATORY]
    --output_dir        Directory path for output files [MANDATORY]

---------------
    --ftcaller          Name of the fusion caller to be run. Either <arriba> or <fusioncatcher> or <both>. Defaults to <both> if not specified
    --hla_typing        Set to <true> if HLA typing subworkflow is required. Defaults to <false> when not specified
    --hla_typing_dir    Directory path to WES or RNA-seq sequencing data to run HLA typing on. Required when --hla_typing is set to <true>
    --hla-only          Setting to run just the HLA typing subpipeline. Default is set to <false>
    --trimming          Set to <true> to perform read trimming on input files (only works with FASTQ inputs)
    --help              Print this help message and exit
    
    """.stripIndent()
}

def create_hla_reads_channel(dir_path) {
    def hla_input_files_ch = Channel.empty()  // Initialize with empty channel
    
    // find bam files if any
    // Check for bam files existence first
    def bam_files = file("${dir_path}/*.{bam}{,.bai}")
    def has_bam = bam_files.size() > 0

    if (has_bam) {
        log.info "[STATUS] Found BAM files..."
        hla_input_files_ch = Channel.fromPath("${dir_path}/*.{bam,bai}")
            .map { file -> 
                // Get filename without extension
                def name = file.name.replaceAll(/\.(bam|bai)$/, '')
                tuple(name, file)
            }
            .groupTuple()  // Group by sample name
            .map { sample_name, files -> 
                // Sort to ensure BAM comes before BAI
                def sorted_files = files.sort { a, _b -> 
                    a.name.endsWith("bam") ? -1 : 1  // BAM files come first
                }
                tuple(sample_name, sorted_files)
            }
    } else {
        log.warn "No BAM files found. Searching for FASTQ files..."
    }

    // find fastq files if any
    // Check for fastq files existence first
    def fastq_files = file("${dir_path}/*{R,r}{1,2}*.{fastq,fq}{,.gz}")
    def has_fastq = fastq_files.size() > 0

    if (has_fastq) {
        log.info "[STATUS] Found FASTQ files. Creating final input channel..."
        def reads_files_ch = Channel.fromFilePairs("${dir_path}/*{R,r}{1,2}*.{fastq,fq}{,.gz}")
            .toSortedList( { a, b -> a[0] <=> b[0] } )
            .flatMap()
        return hla_input_files_ch.mix(reads_files_ch)
    } else {
        log.warn "No FASTQ files found."
        if (has_bam) {
            log.info "Only BAM files found. Proceeding with HLA typing using BAM files..."
            return hla_input_files_ch
        } else {
            log.error "No valid input files found in ${dir_path}. Exiting..."
            exit 1
        }
    }
}

///////////////////////////////////////////////////////////////////////////

//// READ TRIMMING
workflow TRIM_READS {
    take:
        fastq_dir
    main:
        if (!file(fastq_dir).exists() || !file(fastq_dir).isDirectory()) {
            log.error "The input directory is not valid."
            exit 1
        }

        TRIM_READS_FASTP(fastq_dir)

}

//// HLA TYPING
workflow TYPE_HLAS {
    take:
        hla_typing_dir
    
    main:
        if (!file(hla_typing_dir).exists() || !file(hla_typing_dir).isDirectory()) {
            log.error "The HLA typing input directory is not valid."
            exit 1
        }

        HLAReads_ch = create_hla_reads_channel(hla_typing_dir)
        HLAReads_ch.view()
        //preprocessed_ch = PREPROC_HLA_TYPING_INPUT_SAMPICARD(HLAReads_ch)
        //preprocessed_ch.view()
        //TYPE_HLA_ALLELES_HLAHD(preprocessed_ch)
}


// Fusion Analysis
workflow CALL_FUSIONS {
    take:
        alignedBams_ch
    
    main:

        // Handle different fusion caller scenarios
        if (params.ftcaller == 'arriba') {
            arResultTuple = CALL_FUSION_TRANSCRIPTS_AR(alignedBams_ch)
            def DUMMY_FILE = file("${projectDir}/assets/DUMMY_FILE", checkIfExists: false)
            input_with_dummy_ch = arResultTuple.map { sampleName, ftFile -> 
                [sampleName, ftFile, DUMMY_FILE] 
            }
            PREDICT_CODING_SEQ_AGFUSION(input_with_dummy_ch)
        }
        else if (params.ftcaller == 'fusioncatcher') {
            fcResultTuple = CALL_FUSION_TRANSCRIPTS_FC(alignedBams_ch)
            def DUMMY_FILE = file("${projectDir}/assets/DUMMY_FILE", checkIfExists: false)
            input_with_dummy_ch = fcResultTuple.map { sampleName, ftFile -> 
                [sampleName, ftFile, DUMMY_FILE] 
            }
            PREDICT_CODING_SEQ_AGFUSION(input_with_dummy_ch)
        }
        else if (params.ftcaller == 'both') {
            arResultTuple = CALL_FUSION_TRANSCRIPTS_AR(alignedBams_ch)
            fcResultTuple = CALL_FUSION_TRANSCRIPTS_FC(alignedBams_ch)
            
            combinedResults_ch = arResultTuple.arriba_fusion_tuple
                .join(fcResultTuple.fuscat_fusion_tuple, by: 0)
                .map { sampleName, arFile, fcFile -> tuple(sampleName, arFile, fcFile) }
            
            PREDICT_CODING_SEQ_AGFUSION(combinedResults_ch)
            COLLATE_FUSIONS_POLARS(combinedResults_ch)
        }
}

// Main workflow
workflow {
    // Show help message if requested
    if (params.help) {
        helpMessage()
        exit 1
    }

    // Input validation
    if (params.hla_only && !params.hla_typing_dir) {
        error "HLA typing directory must be specified when running in HLA-only mode."
    }

    if (!params.hla_only && !params.input_dir) {
        error "The input directory path (--input_dir) is not provided."
    }

    // Execute workflows based on parameters
    if (params.hla_only) {
        log.info "[STATUS] Running HLA typing workflow only..."

        def input_fastq_files = file("${params.hla_typing_dir}/*{R,r}{1,2}*.{fastq,fq}{,.gz}")
        def has_input_fastq = input_fastq_files.size() > 0

        if (has_input_fastq) {
            if (params.trimming) {
                log.info "[STATUS] HLA input directory contains FASTQ files and trimming is requested. Running FASTP on FASTQ files..."
                ReadPairs_ch = Channel.fromFilePairs("${params.hla_typing_dir}/*{R,r}{1,2}*.{fastq,fq}{,.gz}", checkIfExists: true)
                    .ifEmpty { 
                        error "No valid input FASTQ read files found in HLA typing input directory. Skipping trimming..."
                        exit 1
                    }
                .toSortedList( { a, b -> a[0] <=> b[0] } )
                .flatMap()

                ReadPairs_ch.view()
                //TRIM_READS(params.hla_typing_dir)
            } else {
                log.warn "[WARNING] FASTQ files are found but but trimming not requested. Proceeding without trimming..."
            }
        } else {
            log.warn "[WARNING] No FASTQ files found in HLA typing directory. Now checking for BAM files..."
        }
        
        //TYPE_HLAS(params.hla_typing_dir)

    } else {
        // Check main input files if not in HLA-only mode
        def input_fastq_files = file("${params.input_dir}/*{R,r}{1,2}*.{fastq,fq}{,.gz}")
        def has_input_fastq = input_fastq_files.size() > 0

        if (params.hla_typing) {
            log.info "[STATUS] Running HLA typing workflow..."
            // Check HLA input files
            def hla_fastq_files = file("${params.hla_typing_dir}/*{R,r}{1,2}*.{fastq,fq}{,.gz}")
            def has_hla_fastq = hla_fastq_files.size() > 0
            
            if (params.trim_reads_for_hla && has_hla_fastq) {
                log.info "[STATUS] HLA input files are FASTQ and trimming was requested. Running FASTP..."
                TRIM_READS(params.hla_typing_dir)
            } else if (params.trim_reads_for_hla && !has_hla_fastq) {
                log.warn "[WARNING] Trimming was requested but HLA input files are not FASTQ. Skipping trimming step."
            }
            
            //TYPE_HLAS(params.hla_typing_dir)
        }
        
        log.info "[STATUS] Preprocessing data for main neoantigen modules..."
        if (params.trim_reads_for_main && has_input_fastq) {
            log.info "[STATUS] Input files are FASTQ and trimming was requested. Running FASTP..."
            TRIM_READS(params.input_dir)
        } else if (params.trim_reads_for_main && !has_input_fastq) {
            log.warn "[WARNING] Trimming was requested but input files are not FASTQ. Skipping trimming step."
        }

    }

    workflow.onComplete = {
        println "Pipeline completed at: $workflow.complete"
        println "Execution status: ${ workflow.success ? 'OK' : 'failed' }"
    }
}
